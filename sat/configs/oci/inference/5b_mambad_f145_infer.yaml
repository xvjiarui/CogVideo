args:
  latent_channels: 16
  mode: inference
  load: "checkpoints/CogVideoX-5b-sat/transformer"
  batch_size: 1
  input_type: txt
  input_file: configs/test.txt
  sampling_num_frames: 37  # Must be 13, 11 or 9
  sampling_fps: 8
  bf16: True
  output_dir: output/inference
  force_inference: True

model:
  scale_factor: 0.7 # different from cogvideox_2b_infer.yaml
  disable_first_stage_autocast: true
  log_keys:
    - txt
  
  denoiser_config:
    target: sgm.modules.diffusionmodules.denoiser.DiscreteDenoiser
    params:
      num_idx: 1000
      quantize_c_noise: False

      weighting_config:
        target: sgm.modules.diffusionmodules.denoiser_weighting.EpsWeighting
      scaling_config:
        target: sgm.modules.diffusionmodules.denoiser_scaling.VideoScaling
      discretization_config:
        target: sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization
        params:
          shift_scale: 1.0 # different from cogvideox_2b_infer.yaml

  network_config:
    target: dit_mamba_video_concat.DiffusionTransformer
    params:
      time_embed_dim: 512
      elementwise_affine: True
      # num_frames: 49
      num_frames: 145
      time_compressed_rate: 4
      latent_width: 90
      latent_height: 60
      num_layers: 42 # different from cogvideox_2b_infer.yaml
      patch_size: 2
      in_channels: 16
      out_channels: 16
      hidden_size: 3072 # different from cogvideox_2b_infer.yaml
      adm_in_channels: 256
      num_attention_heads: 48 # different from cogvideox_2b_infer.yaml

      transformer_args:
        checkpoint_activations: True
        vocab_size: 1
        max_sequence_length: 64
        layernorm_order: pre
        skip_init: false
        model_parallel_size: 1
        is_decoder: false

      modules:
        pos_embed_config:
          target: dit_mamba_video_concat.Rotary3DPositionEmbeddingMixin # different from cogvideox_2b_infer.yaml
          params:
            hidden_size_head: 64
            text_length: 226
            # theta: 50000

        patch_embed_config:
          target: dit_mamba_video_concat.ImagePatchEmbeddingMixin
          params:
            text_hidden_size: 4096

        adaln_layer_config:
          target: dit_mamba_video_concat.AdaLNMixin
          params:
            qk_ln: True

        final_layer_config:
          target: dit_mamba_video_concat.FinalLayerMixin

        mamba_attn_config:
          target: dit_mamba_video_concat.MambaAttentionLayerMixin
          params:
            # temporal_length: 13
            # temporal_length: 37
            prefix_temporal_length: 1
            attn_length: 12
            # prefix_temporal_length: 5
            # attn_length: 8
            mamba_hidden_size: 0
            mamba_order: post

  conditioner_config:
    target: sgm.modules.GeneralConditioner
    params:
      emb_models:
        - is_trainable: false
          input_key: txt
          ucg_rate: 0.1
          target: sgm.modules.encoders.modules.FrozenT5Embedder
          params:
            model_dir: "checkpoints/t5-v1_1-xxl"
            max_length: 226

  # NOTE(xvjiarui): I tried differnet values for the temporal tiling window, for 450 frames
  # 8, 2: 118s, 215s
  # 16, 4: 94s, 180s
  # 32, 8: 85s, OOM
  encoder_temporal_tiling_window: 16
  decoder_temporal_tiling_window: 2
  first_stage_config:
    target: vae_modules.autoencoder.VideoAutoencoderInferenceWrapper
    params:
      cp_size: 1
      ckpt_path: "checkpoints/CogVideoX-5b-sat/vae/3d-vae.pt"
      ignore_keys: [ 'loss' ]

      loss_config:
        target: torch.nn.Identity

      regularizer_config:
        target: vae_modules.regularizers.DiagonalGaussianRegularizer

      encoder_config:
        target: vae_modules.cp_enc_dec.ContextParallelEncoder3D
        params:
          double_z: true
          z_channels: 16
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [ 1, 2, 2, 4 ]
          attn_resolutions: [ ]
          num_res_blocks: 3
          dropout: 0.0
          gather_norm: True

      decoder_config:
        target: vae_modules.cp_enc_dec.ContextParallelDecoder3D
        params:
          double_z: True
          z_channels: 16
          resolution: 256
          in_channels: 3
          out_ch: 3
          ch: 128
          ch_mult: [ 1, 2, 2, 4 ]
          attn_resolutions: [ ]
          num_res_blocks: 3
          dropout: 0.0
          gather_norm: False

  loss_fn_config:
    target: sgm.modules.diffusionmodules.loss.VideoDiffusionLoss
    params:
      offset_noise_level: 0
      sigma_sampler_config:
        target: sgm.modules.diffusionmodules.sigma_sampling.DiscreteSampling
        params:
          uniform_sampling: True
          num_idx: 1000
          discretization_config:
            target: sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization
            params:
              shift_scale: 1.0 # different from cogvideox_2b_infer.yaml

  sampler_config:
    # target: sgm.modules.diffusionmodules.sampling.VPSDEDPMPP2MSampler
    target: sgm.modules.diffusionmodules.sampling.VPODEDPMPP2MSampler
    params:
      num_steps: 50
      verbose: True

      discretization_config:
        target: sgm.modules.diffusionmodules.discretizer.ZeroSNRDDPMDiscretization
        params:
          shift_scale: 1.0 # different from cogvideox_2b_infer.yaml

      guider_config:
        target: sgm.modules.diffusionmodules.guiders.DynamicCFG
        params:
          scale: 6
          exp: 5
          num_steps: 50